on:
  workflow_dispatch:
    inputs: {}
  push:
    branches:
    - main
jobs:
  gcs_source_archive_bucket_upload:
    runs-on: ubuntu-latest
    env:
      # organization secrets
      GCP_SA_KEY: ${{ secrets.GCP_SA_KEY }}
      GH_ORGANIZATION_TOKEN: ${{ secrets.GH_ORGANIZATION_TOKEN }}
      # repository secrets
      DATA_PROJECT_ID: ${{ secrets.DATA_PROJECT_ID }}
      SOURCE_ARCHIVE_BUCKET_NAME: ${{ secrets.SOURCE_ARCHIVE_BUCKET_NAME }}
    steps:
      - name: checkout
        uses: actions/checkout@v2
      - name: setup gcloud
        uses: google-github-actions/setup-gcloud@master
        with:
          project_id: ${{ env.DATA_PROJECT_ID }}
          service_account_key: ${{ env.GCP_SA_KEY }}
          export_default_credentials: true
      - name: zip nodejs12 cloud functions
        run: |
          current_dir=$(pwd)
          NODEJS12_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH="${current_dir}/${GITHUB_SHA}/nodejs12"
          mkdir -p "${NODEJS12_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH}"
          find nodejs12 -maxdepth 1 -mindepth 1 -type d | while read function_path; do
            function_name="$(echo ${function_path} | rev | cut -d'/' -f 1 | rev)"
            cd "${function_path}"
            zip -r "${NODEJS12_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH}/${function_name}.zip" *
            cd "${current_dir}"
          done
          echo "NODEJS12_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH=${NODEJS12_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH}" >> "${GITHUB_ENV}"
      - name: upload nodejs12 cloud functions
        uses: google-github-actions/upload-cloud-storage@main
        with:
          path: ${{ env.NODEJS12_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH }}
          destination: ${{ env.SOURCE_ARCHIVE_BUCKET_NAME }}/${{ github.sha }}
          gzip: false
      - name: zip python38 cloud functions
        run: |
          current_dir=$(pwd)
          PYTHON38_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH="${current_dir}/${GITHUB_SHA}/python38"
          mkdir -p "${PYTHON38_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH}"
          find python38 -maxdepth 1 -mindepth 1 -type d | while read function_path; do
            function_name="$(echo ${function_path} | rev | cut -d'/' -f 1 | rev)"
            cd "${function_path}"
            zip -r "${PYTHON38_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH}/${function_name}.zip" *
            cd "${current_dir}"
          done
          echo "PYTHON38_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH=${PYTHON38_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH}" >> "${GITHUB_ENV}"
      - name: upload python38 cloud functions
        uses: google-github-actions/upload-cloud-storage@main
        with:
          path: ${{ env.PYTHON38_SOURCE_ARCHIVE_BUCKET_OBJECT_PATH }}
          destination: ${{ env.SOURCE_ARCHIVE_BUCKET_NAME }}/${{ github.sha }}
          gzip: false
      - name: checkout infra-live
        uses: actions/checkout@v2
        with:
          repository: neuralnetes/infra-live
          path: infra-live
      - name: run infra-live github_actions_workflow_dispatch_terragrunt_run_all_apply script
        working-directory: infra-live
        run: ./hack/github-actions/workflow_dispatch_infra_live_terragrunt_run_all_apply.sh "${GH_ORGANIZATION_TOKEN}" "master"
